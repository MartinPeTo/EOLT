{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling the data with smote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#smote-variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/martin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Import\n",
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to create X and y:\n",
    "X = df.drop(['SN','status'], axis=1)\n",
    "y = df.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4628"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4628"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of PASS/FAIL values:\n",
      "[['F' 'P']\n",
      " [2314 2314]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(y_resampled, return_counts=True)\n",
    "print(\"Frequency of PASS/FAIL values:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a new dataframe with the resampled data:\n",
    "df_oversample = pd.DataFrame(data=X_resampled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the Y_resampled:\n",
    "df_oversample['status'] = y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating train set into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over = df_oversample.drop('status', axis=1)\n",
    "y_over = df_oversample.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A_Indep_Front             0\n",
       "A_RollSpeed_Front         0\n",
       "A_R2R2W_Front             0\n",
       "KM_Front                  0\n",
       "KM_DEV_Front              0\n",
       "A_Indep_Rear              0\n",
       "A_RollSpeed_Rear          0\n",
       "A_R2R2W_Rear              0\n",
       "KM_Rear                   0\n",
       "KM_DEV_Rear               0\n",
       "TR_PWM_SLOP_FRONT         0\n",
       "TR_PWM_OFFSET_FRONT       0\n",
       "R2_Front                  0\n",
       "TR_AccuENC_RATIO_FRONT    0\n",
       "TR_PWM_SLOP_REAR          0\n",
       "TR_PWM_OFFSET_REAR        0\n",
       "R2_Rear                   0\n",
       "TR_AccuENC_RATIO_REAR     0\n",
       "status                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oversample.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4628\n",
      "4628\n"
     ]
    }
   ],
   "source": [
    "print(len(X_over))\n",
    "print(len(y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Normalizer().fit(X_train)\n",
    "norm_X = transformer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Normalizer().fit(X_test)\n",
    "norm_X_test = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': [5,7,9,11,15],\n",
    "              'weights': ['uniform'], #We only use uniform because 'distance' overfit a lot.\n",
    "              'leaf_size': [10, 20, 30, 50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS = GridSearchCV(KNN, param_grid, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] leaf_size=20, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=5, weights=uniform, score=0.765, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=5, weights=uniform, score=0.722, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=5, weights=uniform, score=0.753, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=5, weights=uniform, score=0.772, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=5, weights=uniform, score=0.739, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=7, weights=uniform, score=0.744, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=7, weights=uniform ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  leaf_size=20, n_neighbors=7, weights=uniform, score=0.717, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=7, weights=uniform, score=0.743, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=7, weights=uniform, score=0.759, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=7, weights=uniform, score=0.728, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=9, weights=uniform, score=0.738, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=9, weights=uniform, score=0.713, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=9, weights=uniform, score=0.719, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=9, weights=uniform, score=0.749, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=20, n_neighbors=9, weights=uniform, score=0.724, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=11, weights=uniform, score=0.725, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=11, weights=uniform, score=0.707, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=11, weights=uniform, score=0.715, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=11, weights=uniform, score=0.743, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=11, weights=uniform, score=0.707, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=15, weights=uniform, score=0.713, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=15, weights=uniform, score=0.677, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=15, weights=uniform, score=0.704, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=15, weights=uniform, score=0.732, total=   0.0s\n",
      "[CV] leaf_size=20, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=20, n_neighbors=15, weights=uniform, score=0.693, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=5, weights=uniform, score=0.765, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=5, weights=uniform, score=0.722, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=5, weights=uniform, score=0.753, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=5, weights=uniform, score=0.772, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=5, weights=uniform, score=0.739, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=7, weights=uniform, score=0.744, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=7, weights=uniform, score=0.717, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=7, weights=uniform, score=0.743, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=7, weights=uniform, score=0.759, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=7, weights=uniform, score=0.728, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=9, weights=uniform, score=0.738, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=9, weights=uniform, score=0.713, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=9, weights=uniform, score=0.719, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=9, weights=uniform, score=0.749, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=30, n_neighbors=9, weights=uniform, score=0.724, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=11, weights=uniform, score=0.725, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=11, weights=uniform, score=0.707, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=11, weights=uniform, score=0.715, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=11, weights=uniform, score=0.743, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=11, weights=uniform, score=0.707, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=15, weights=uniform, score=0.713, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=15, weights=uniform, score=0.677, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=15, weights=uniform, score=0.704, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=15, weights=uniform, score=0.732, total=   0.0s\n",
      "[CV] leaf_size=30, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=30, n_neighbors=15, weights=uniform, score=0.693, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=5, weights=uniform, score=0.765, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=5, weights=uniform, score=0.722, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=5, weights=uniform, score=0.753, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=5, weights=uniform, score=0.772, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=5, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=5, weights=uniform, score=0.739, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=7, weights=uniform, score=0.744, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=7, weights=uniform, score=0.717, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=7, weights=uniform, score=0.743, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=7, weights=uniform, score=0.759, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=7, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=7, weights=uniform, score=0.728, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=9, weights=uniform, score=0.738, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=9, weights=uniform, score=0.713, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=9, weights=uniform ....................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  leaf_size=50, n_neighbors=9, weights=uniform, score=0.719, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=9, weights=uniform, score=0.749, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=9, weights=uniform ....................\n",
      "[CV]  leaf_size=50, n_neighbors=9, weights=uniform, score=0.724, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=11, weights=uniform, score=0.725, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=11, weights=uniform, score=0.707, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=11, weights=uniform, score=0.715, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=11, weights=uniform, score=0.743, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=11, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=11, weights=uniform, score=0.707, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=15, weights=uniform, score=0.713, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=15, weights=uniform, score=0.677, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=15, weights=uniform, score=0.704, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=15, weights=uniform, score=0.732, total=   0.0s\n",
      "[CV] leaf_size=50, n_neighbors=15, weights=uniform ...................\n",
      "[CV]  leaf_size=50, n_neighbors=15, weights=uniform, score=0.693, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=100,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=21, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'leaf_size': [20, 30, 50],\n",
       "                         'n_neighbors': [5, 7, 9, 11, 15],\n",
       "                         'weights': ['uniform']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.fit(norm_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 20, 'n_neighbors': 5, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check the best params of the search grid:\n",
    "GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the model with the selected parameters:\n",
    "KNN = KNeighborsClassifier(leaf_size=100, n_neighbors=9, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=100, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(norm_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of the test dataset:\n",
    "y_train_pred = KNN.predict(norm_X)\n",
    "y_pred = KNN.predict(norm_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN MODEL METRICS:\n",
      "The F1 score is: 0.8000239329124325\n",
      "The accuracy is: 0.8014586709886548\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1650,  220],\n",
       "       [ 515, 1317]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check scores with train:\n",
    "f1 = f1_score(y_train, y_train_pred, labels=None, pos_label=1, average='weighted')\n",
    "accuracy = accuracy_score(y_train, y_train_pred)\n",
    "conf = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "print ('TRAIN MODEL METRICS:')\n",
    "print('The F1 score is: ' + str(f1))\n",
    "print('The accuracy is: ' + str(accuracy))\n",
    "print('Confusion matrix:')\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MODEL METRICS:\n",
      "The F1 score is: 0.7119062929635427\n",
      "The accuracy is: 0.7159827213822895\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[378,  66],\n",
       "       [197, 285]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check scores with test:\n",
    "f1 = f1_score(y_test, y_pred, labels=None, pos_label=1, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print ('TEST MODEL METRICS:')\n",
    "print('The F1 score is: ' + str(f1))\n",
    "print('The accuracy is: ' + str(accuracy))\n",
    "print('Confusion matrix:')\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the metrics with only the selected data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_real = KNN.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MODEL METRICS:\n",
      "The F1 score is: 0.7490140448768295\n",
      "The accuracy is: 0.7023988005997002\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 272,   82],\n",
       "       [ 712, 1602]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check scores:\n",
    "f1 = f1_score(y, y_pred_real, labels=None, pos_label=1, average='weighted')\n",
    "accuracy = accuracy_score(y, y_pred_real)\n",
    "conf = confusion_matrix(y, y_pred_real)\n",
    "\n",
    "print ('TEST MODEL METRICS:')\n",
    "print('The F1 score is: ' + str(f1))\n",
    "print('The accuracy is: ' + str(accuracy))\n",
    "print('Confusion matrix:')\n",
    "conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
